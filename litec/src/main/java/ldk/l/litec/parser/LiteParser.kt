package ldk.l.litec.parser

import ldk.l.litec.util.Span
import ldk.l.litec.util.Stdout
import ldk.l.litec.util.error.CompilerError
import ldk.l.litec.util.error.ErrorType

class LiteParser(
    private val lexer: LiteLexer,
    private val filePath: String
) {
    private val errors: MutableList<CompilerError.ParserError> = mutableListOf()

    private var currentToken: Token? = lexer.next()

    fun hasError() = errors.isNotEmpty()
    fun printErrors() {
        errors.forEach {
            Stdout.println(it)
        }
    }

    private fun consume(): Token? {
        val prev = currentToken
        currentToken = lexer.next()
        return prev
    }

    private fun current() = currentToken

    /**
     * âœ… åˆ¤æ–­å½“å‰ token æ˜¯å¦æ˜¯æŸä¸ªç±»å‹
     */
    private fun match(type: TokenType): Boolean {
        if (current()?.type == type) {
            consume()
            return true
        }
        return false
    }

    /**
     * âœ… æœŸæœ›æŸä¸ª tokenï¼Œå¦‚æœä¸æ˜¯å°±æŠ¥é”™
     */
    private fun expect(type: TokenType, error: CompilerError.ParserError): Token? {
        if (current()?.type == type) {
            return consume()
        } else {
            errors.add(error)
            return null
        }
    }

    private fun addError(
        span: Span,
        errorType: ErrorType,
        expected: String?,
        found: String?,
        filePath: String? = null,
        templateArgs: Array<out Any> = emptyArray(),
        note: String? = null,
        help: String? = null
    ) {
        errors.add(
            CompilerError.ParserError(
                span,
                errorType,
                expected,
                found,
                filePath,
                templateArgs,
                note,
                help
            )
        )
    }

    /**
     * åŒæ­¥åˆ°ä¸‹ä¸€ä¸ªè¯­å¥è¾¹ç•Œ
     */
    fun synchronize() {
        while (!match(TokenType.EOF) && !isAtStatementBoundary()) {
            consume()
        }
        if (match(TokenType.EOF)) return
        consume() // è·³è¿‡è¾¹ç•Œ tokenï¼ˆå¦‚ ; }
    }

    private fun isAtStatementBoundary(): Boolean = when (current()?.type) {
        TokenType.SEMICOLON,
        TokenType.RBRACE,
        TokenType.LET,
        TokenType.FUN,
        TokenType.IF,
        TokenType.WHILE,
        TokenType.RETURN -> true
        else -> false
    }

    fun lookahead(n: Int): Token? {
        val snapshot = lexer.checkpoint()
        return try {
            repeat(n-1) { lexer.next() }
            lexer.next()
        } finally {
            lexer.restore(snapshot)
        }
    }

    /**
     * ğŸ” å®‰å…¨å›æº¯ï¼šå°è¯•æ‰§è¡Œä¸€ä¸ªè§£æå‡½æ•°
     * æˆåŠŸ â†’ è¿”å›ç»“æœ
     * å¤±è´¥ â†’ è‡ªåŠ¨å›é€€ï¼Œè¿”å› null
     */
    // å·¥å…·å‡½æ•°
    private inline fun <T> backtrack(crossinline block: () -> T?): T? {
        val snapshot = lexer.checkpoint()
        val result = block()
        if (result == null) {
            lexer.restore(snapshot)
        }
        return result
    }

    fun parseExpr(minPrecedence: Int = 0): Expr? {
        var left = parsePrefix() ?: return null

        while (true) {
            val op = current() ?: break

            val infixPrecedence = op.type.leftBindingPower()

            if (infixPrecedence < minPrecedence) {
                break
            }

            consume()

            left = parseInfix(left,op)
                ?: return null
        }

        return left
    }

    private fun parseInfix(left: Expr, token: Token): Expr? {
        return when (token.type) {
            // å¤„ç†äºŒå…ƒæ“ä½œç¬¦ (+, -, *, /, ==, <, &&, || ç­‰)
            TokenType.PLUS,
            TokenType.MINUS,
            TokenType.STAR,
            TokenType.SLASH,
            TokenType.PERCENT,
            TokenType.EQUAL_EQUAL,
            TokenType.BANG_EQUAL,
            TokenType.LESS,
            TokenType.LESS_EQUAL,
            TokenType.GREATER,
            TokenType.GREATER_EQUAL,
            TokenType.AND,
            TokenType.OR,
            TokenType.EQUAL,
            TokenType.PLUS_EQUAL,
            TokenType.MINUS_EQUAL,
            TokenType.STAR_EQUAL,
            TokenType.SLASH_EQUAL,
            TokenType.PERCENT_EQUAL -> {
                // 1. è®¡ç®—å³æ“ä½œæ•°çš„æœ€å°ä¼˜å…ˆçº§
                val nextMinPrecedence = if (token.type.isRightAssociative()) {
                    token.type.leftBindingPower() // å…è®¸ç›¸åŒä¼˜å…ˆçº§
                } else {
                    token.type.leftBindingPower() + 1 // å¼ºåˆ¶å·¦ç»“åˆ
                }

                // 2. è§£æå³æ“ä½œæ•°
                val right = parseExpr(nextMinPrecedence) ?: return null

                // 3. æ„é€ äºŒå…ƒè¡¨è¾¾å¼èŠ‚ç‚¹
                Expr.BinaryExpr(left.span.extendTo(right.span), left, right, token)
            }

            // å¤„ç†å‡½æ•°è°ƒç”¨ a()
            TokenType.LPAREN -> {
                // æ¶ˆè´¹ '(' å·²ç»åœ¨ parseExpr çš„å¾ªç¯ä¸­å®Œæˆ
                val arguments = mutableListOf<Expr>()
                // è§£æå‚æ•°åˆ—è¡¨ï¼Œç›´åˆ°é‡åˆ° ')'
                if (current()?.type != TokenType.RPAREN) { // å¦‚æœä¸æ˜¯ç©ºå‚
                    do {
                        val arg = parseExpr() ?: break
                        arguments.add(arg)
                    } while (match(TokenType.COMMA))
                }
                // æœŸæœ› ')'
                val closeParen = expect(
                    TokenType.RPAREN,
                    error = CompilerError.ParserError(
                        span = token.span,
                        errorType = ErrorType.MISSING_PARENTHESIS,
                        expected = ")",
                        found = current()?.lexeme,
                        filePath = filePath,
                        help = "æ·»åŠ ä¸Š ')'"
                    )
                ) ?: return null // å¦‚æœç¼ºå°‘ ')', è¿”å› null

                Expr.CallExpr(left.span.extendTo(closeParen.span), left, arguments)
            }

            // å¤„ç†æ•°ç»„ç´¢å¼• a[0]
            TokenType.LBRACKET -> {
                // æ¶ˆè´¹ '[' å·²åœ¨å¾ªç¯ä¸­å®Œæˆ
                val index = parseExpr() ?: return null
                val closeBracket = expect(
                    TokenType.RBRACKET,
                    error = CompilerError.ParserError(
                        span = token.span,
                        errorType = ErrorType.MISSING_PARENTHESIS,
                        expected = "]",
                        found = current()?.lexeme,
                        filePath = filePath,
                        help = "æ·»åŠ ä¸Š ']'"
                    )
                ) ?: return null
                Expr.IndexExpr(left.span.extendTo(closeBracket.span), left, index)
            }

            // å¤„ç†æˆå‘˜è®¿é—® a.b
            TokenType.DOT -> {
                val identifier = expect(
                    TokenType.IDENTIFIER,
                    error = CompilerError.ParserError(
                        span = current()!!.span,
                        errorType = ErrorType.EMPTY_EXPRESSION,
                        expected = "identifier",
                        found = current()?.lexeme,
                        filePath = filePath,
                        help = "`.` ååº”è·Ÿä¸€ä¸ªæ ‡è¯†ç¬¦"
                    )
                ) ?: return null
                Expr.MemberAccessExpr(left.span.extendTo(identifier.span), left, identifier)
            }

            // å¤„ç†åç¼€æ“ä½œç¬¦ i++, i--
            TokenType.PLUS_PLUS, TokenType.MINUS_MINUS -> {
                // è¿™é‡Œé€šå¸¸æ„é€ åç¼€æ“ä½œè¡¨è¾¾å¼èŠ‚ç‚¹
                Expr.PostfixExpr(left.span.extendTo(token.span), left,token)
            }

            else -> {
                // ç†è®ºä¸Šä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œå› ä¸º parseExpr çš„å¾ªç¯åªå¯¹ leftBindingPower > 0 çš„ token è°ƒç”¨ parseInfix
                addError(
                    span = token.span,
                    errorType = ErrorType.UNEXPECTED_TOKEN,
                    expected = "infix operator",
                    found = token.lexeme,
                    filePath = filePath
                )
                null
            }
        }
    }

    private fun parsePrefix(): Expr? {
        return when (val type = current()?.type) {
            // å­—é¢é‡
            TokenType.TRUE -> Expr.LiteralExpr(current()!!.span, true).also { consume() }
            TokenType.FALSE -> Expr.LiteralExpr(current()!!.span, false).also { consume() }
            TokenType.NULL -> Expr.LiteralExpr(current()!!.span, null).also { consume() }
            TokenType.INT -> Expr.LiteralExpr(current()!!.span, current()!!.lexeme.toInt()).also { consume() }
            TokenType.FLOAT -> Expr.LiteralExpr(current()!!.span, current()!!.lexeme.toDouble()).also { consume() }
            TokenType.STRING -> Expr.LiteralExpr(current()!!.span, current()!!.lexeme).also { consume() }

            // æ ‡è¯†ç¬¦
            TokenType.IDENTIFIER -> Expr.VariableExpr(current()!!.span, current()!!.lexeme).also { consume() }

            // å‰ç¼€æ“ä½œç¬¦
            TokenType.BANG, TokenType.MINUS, TokenType.PLUS -> {
                val op = consume()
                val expr = parseExpr(TokenType.MINUS.leftBindingPower()) ?: return null
                Expr.UnaryExpr(op!!.span.extendTo(expr.span), op, expr)
            }

            // æ‹¬å·è¡¨è¾¾å¼
            TokenType.LPAREN -> {
                val start = consume() // (
                val expr = parseExpr()

                val closeParen = expect(
                    TokenType.RPAREN,
                    error = CompilerError.ParserError(
                        span = start!!.span.extendTo(current()!!.span),
                        errorType = ErrorType.MISSING_PARENTHESIS,
                        expected = ")",
                        found = current()?.lexeme,
                        filePath = filePath,
                        help = "æ·»åŠ ä¸Š ')'"
                    )
                )
                if (closeParen == null) {
                    return null // å³æ‹¬å·ç¼ºå¤±ï¼Œæ•´ä¸ªæ‹¬å·è¡¨è¾¾å¼å¤±è´¥
                }
                expr
            }

            else -> null
        }
    }
}